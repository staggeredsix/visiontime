version: "3.9"

services:
  triton:
    image: nvcr.io/nvidia/tritonserver:24.05-py3
    restart: unless-stopped
    command: ["tritonserver", "--model-repository=/models", "--log-verbose=1"]
    volumes:
      - ./models:/models:ro
    ports:
      - "8000:8000" # HTTP
      - "8001:8001" # gRPC
      - "8002:8002" # Metrics
    # modern GPU enablement for docker compose
    gpus: all

  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    environment:
      - TRITON_GRPC_URL=triton:8001
      - CONFIG_PATH=/config/cameras.yaml
    depends_on:
      - triton
    volumes:
      - ./config:/config
      - ./models:/models:ro
    ports:
      - "8080:8080"
    # orchestrator also needs CUDA
    gpus: all

  frontend:
    image: nginx:1.27-alpine
    depends_on:
      - orchestrator
    volumes:
      - ./frontend:/usr/share/nginx/html:ro
      - ./frontend/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./frontend/ssl:/etc/nginx/certs:ro
    ports:
      - "8090:443"
